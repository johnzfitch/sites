[caddy]: https://caddyserver.com
[nixos]: https://nixos.org
[toml]: https://toml.io
[go]: https://go.dev

# sites

Mutable topology layer for static sites on <abbr title="Network Information eXtensions Operating System">NixOS</abbr>.

NixOS is immutable infrastructure. `sites` is mutable topology.

<kbd>git push</kbd> &rarr; reconcile &rarr; live. No <code>nixos-rebuild</code>. No webhooks. No moving parts.

---

## The idea

Your NixOS config defines *what the server is*&hairsp;&mdash;&hairsp;Caddy, systemd, firewall, users. That's the immutable layer. But *which domains point to which repos*&hairsp;&mdash;&hairsp;that changes weekly. You shouldn't need a full system rebuild to add a landing page.

`sites` is the mutable layer that sits between GitHub and [Caddy][caddy]. It has desired state (<samp>sites.toml</samp>) and actual state (what's on disk). It converges idempotently. Every 60 seconds, or on demand.

```
┌──────────────┐     ┌──────────┐     ┌───────────┐
│   GitHub     │────▶│  sites   │────▶│   Caddy   │
│   (repos)    │     │(reconcile│     │  (serve)   │
│              │     │  + emit) │     │            │
└──────────────┘     └──────────┘     └───────────┘
                          │
                     sites.toml
                    (desired state)
```

One binary. One config file. One log file. 938 lines of Go.

## Quick start

```sh
# Build (or grab the binary from releases)
CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -ldflags="-s -w" -o sites .

# Copy to server
scp sites myserver:/usr/local/bin/

# Create initial config
sites add example.com user/example.com
sites add blog.example.com user/blog --branch main

# Deploy everything
sites sync

# See what happened
sites list
sites log
```

## CLI

<dl>
  <dt><code>sites add &lt;domain&gt; &lt;repo&gt;</code></dt>
  <dd>Add a site to <samp>sites.toml</samp>. Repo can be a full URL or GitHub shorthand (<code>user/repo</code>). Optional flags: <code>--branch</code>, <code>--path</code>, <code>--deploy-key</code>, <code>--private</code>.</dd>
  <dt><code>sites remove &lt;domain&gt;</code></dt>
  <dd>Remove a site from config. Run <code>sites sync</code> after to clean up the directory.</dd>
  <dt><code>sites list</code></dt>
  <dd>Table of all sites: domain, repo, current commit, last update, auth method.</dd>
  <dt><code>sites sync</code></dt>
  <dd>Run the reconciler once. Clones missing repos, pulls stale ones, removes orphans, regenerates the Caddyfile, reloads Caddy if anything changed.</dd>
  <dt><code>sites deploy &lt;domain&gt;</code></dt>
  <dd>Force-pull a single site and reload. For when you don't want to wait 60&nbsp;seconds.</dd>
  <dt><code>sites log [domain]</code></dt>
  <dd>Tail the deploy log (JSON&nbsp;lines). Optional domain filter.</dd>
  <dt><code>sites caddy</code></dt>
  <dd>Print the generated Caddyfile to stdout. Useful for debugging.</dd>
  <dt><code>sites watch</code></dt>
  <dd>Daemon mode: reconcile every 60s. This is what <samp>sitesd.service</samp> runs.</dd>
</dl>

## Config

<samp>sites.toml</samp> lives at <code>/etc/sites/sites.toml</code> by default. Override with <var>SITES_CONFIG</var> env var.

```toml
[global]
root = "/var/lib/sites"             # where repos are cloned
caddyfile = "/etc/caddy/sites.conf" # generated Caddyfile output
log = "/var/lib/sites/deploy.log"   # append-only JSON lines

[sites.example-com]
domain = "example.com"
repo = "https://github.com/user/example.com"
branch = "main"
# path = "dist"                     # optional: serve a subdirectory

[sites.blog-example-com]
domain = "blog.example.com"
repo = "https://github.com/user/blog"
branch = "main"
```

The site key (e.g. `example-com`) becomes the clone directory name under <var>root</var>. The <code>domain</code> field controls the Caddyfile entry.

<details>
<summary>Generated Caddyfile output</summary>

```
# AUTO-GENERATED BY sites — DO NOT EDIT
blog.example.com {
	root * /var/lib/sites/blog-example-com
	file_server
	header {
		X-Deployed-Commit "7bc1e4f"
		-Server
	}
}

example.com {
	root * /var/lib/sites/example-com
	file_server
	header {
		X-Deployed-Commit "a3f8c2d"
		-Server
	}
}
```

Caddy's main config just needs one line added (once):

```
import /etc/caddy/sites.conf
```

</details>

## Private repos &amp; dota

For private repos, `sites` integrates with [dota](https://github.com/definitelynot-ai/dota)&hairsp;&mdash;&hairsp;a post-quantum secrets manager using <abbr title="Module-Lattice-based Key Encapsulation Mechanism, 768-bit security level">ML-KEM-768</abbr>&hairsp;+&hairsp;X25519.

Deploy keys are stored encrypted in dota, extracted to <abbr title="temporary filesystem, backed by RAM — keys never touch disk">tmpfs</abbr> for the duration of a single git operation, then destroyed. Keys never touch persistent storage.

```sh
# 1. Generate a deploy key
ssh-keygen -t ed25519 -f key -N ""

# 2. Add the public key to your GitHub repo
#    → Settings → Deploy keys → Add deploy key

# 3. Store the private key in dota
dota set deploy-key/my-private-site "$(cat key)"

# 4. Add the site with --private (auto-names the dota key)
sites add my-private-site.com user/repo --private

# Or specify the dota key name explicitly:
sites add my-private-site.com user/repo --deploy-key deploy-key/my-private-site
```

<details>
<summary>How it works under the hood</summary>

When `sites sync` encounters a site with a `deploy_key`:

1. Calls `dota get <key-name>` to decrypt the SSH key
2. Writes it to a random filename in `/dev/shm/sites-keys/` (RAM-only on Linux)
3. Sets `GIT_SSH_COMMAND` to use that key with `StrictHostKeyChecking=accept-new` (TOFU model)
4. Converts the HTTPS repo URL to SSH format (`git@github.com:user/repo.git`)
5. Runs the git operation
6. Deletes the key file immediately (also runs on panic via `defer`)

On non-Linux systems (macOS dev machines), falls back to `os.TempDir()`.

</details>

## Daemon setup

Copy `sitesd.service` to your server or wire it into NixOS:

<details>
<summary><samp>sitesd.service</samp> &mdash; systemd unit with sandboxing</summary>

```ini
[Unit]
Description=sites reconciler daemon
After=network-online.target caddy.service
Wants=network-online.target

[Service]
Type=simple
ExecStart=/usr/local/bin/sites watch
Restart=always
RestartSec=10s

# Run as dedicated user
User=sites
Group=sites

# Filesystem
ProtectSystem=strict
ProtectHome=true
PrivateTmp=true
ReadWritePaths=/var/lib/sites /etc/caddy/sites.conf

# Kernel
ProtectKernelTunables=true
ProtectKernelModules=true
ProtectKernelLogs=true
ProtectControlGroups=true

# Process
NoNewPrivileges=true
RestrictSUIDSGID=true

# Network (needs outbound for git fetch)
RestrictAddressFamilies=AF_UNIX AF_INET AF_INET6

# Capabilities
CapabilityBoundingSet=

[Install]
WantedBy=multi-user.target
```

</details>

<details>
<summary>NixOS integration &mdash; two touchpoints</summary>

```nix
# modules/sitesd.nix — ~15 lines
systemd.services.sitesd = {
  description = "sites reconciler";
  wantedBy = [ "multi-user.target" ];
  after = [ "network-online.target" "caddy.service" ];
  serviceConfig = {
    Type = "simple";
    ExecStart = "${sites}/bin/sites watch";
    Restart = "always";
    RestartSec = "10s";
    User = "sites";
    ReadWritePaths = [ "/var/lib/sites" "/etc/caddy/sites.conf" ];
    ProtectSystem = "strict";
    NoNewPrivileges = true;
  };
};
```

And one line in your Caddy config:

```
import /etc/caddy/sites.conf
```

That's it. Everything else is `sites`' problem.

</details>

## Reconciler model

`sites` is a reconciler, not a webhook handler. There is no HTTP surface. No attack surface.

```
Desired (sites.toml)                 Actual (disk)              Action
─────────────────────                ──────────────             ──────
example.com → main                  cloned @ a3f8c2d           git pull (check for update)
blog.example.com → main             missing                    git clone --depth 1
staging.example.com → main          cloned @ 2d9f1a3           git pull (check for update)
(removed old-site.com from config)  cloned                     remove directory
```

After convergence: regenerate Caddyfile, diff against current, reload Caddy only if changed. Every run is idempotent. Crash at any point and the next run re-converges from actual state. No lock files, no stale state, no corruption.

> [!NOTE]
> Git operations shell out to the `git` binary&hairsp;&mdash;&hairsp;not libgit2. Simpler, debuggable, and `git` is already on every NixOS system. The security surface is controlled: we run `git clone <url>` and `git fetch` + `git reset` in controlled directories. No user input touches commands beyond the repo URL from `sites.toml`, which the operator wrote.

## Deploy log

Append-only JSON lines at <samp>/var/lib/sites/deploy.log</samp>:

```jsonl
{"ts":"2026-02-23T20:15:32Z","domain":"example.com","action":"updated","commit":"a3f8c2d","prev":"9e1b3f2","dur_ms":1200}
{"ts":"2026-02-23T20:15:33Z","domain":"blog.example.com","action":"cloned","commit":"7bc1e4f","dur_ms":3400}
{"ts":"2026-02-23T20:16:32Z","domain":"example.com","action":"up-to-date","commit":"a3f8c2d","dur_ms":80}
```

## Architecture

See [`ARCHITECTURE.md`](ARCHITECTURE.md) for eight diagrams covering the system overview, reconcile loop state machine, data flow, CLI workflow, daemon lifecycle, dota integration, atomic writes, and NixOS integration boundaries.

## What this is not

<dl>
  <dt>Not a NixOS module</dt>
  <dd>It's a standalone binary + TOML config + systemd unit. NixOS runs it; NixOS doesn't define it.</dd>
  <dt>Not a webhook handler</dt>
  <dd>No HTTP listener, no attack surface, no ngrok tunnels. It polls. Webhooks are a v2 feature.</dd>
  <dt>Not a build system</dt>
  <dd>It serves static files. If you need <code>npm run build</code>, that's v2.</dd>
  <dt>Not Vercel</dt>
  <dd>It's what Vercel would be if Vercel were 938 lines of Go and respected your infrastructure.</dd>
</dl>

## Roadmap

> [!TIP]
> MVP is done. These are future considerations, not commitments.

1. **Build hooks** &mdash; `build = "npm run build"` in site config, runs after pull
2. **Webhooks** &mdash; optional HTTP endpoint for instant deploy on push (vs.&nbsp;60s&nbsp;poll)
3. **TUI** &mdash; `sites tui` &mdash; live status table, press <kbd>r</kbd> to redeploy, <kbd>l</kbd> for logs
4. **Rollback** &mdash; `sites rollback <domain> [commit]` &mdash; git checkout + reload

## Build

```sh
# Requires Go 1.21+
go build -o sites .

# Static binary for Linux servers
CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -ldflags="-s -w" -o sites .
```

Single dependency: [`BurntSushi/toml`][toml].

## License

MIT
